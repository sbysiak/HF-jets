{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plotting import plot_roc, plot_score_vs_pt, plot_tagging_eff, plot_confusion_matrix, plot_xgb_learning_curve, plot_score_distr, plot_signal_significance\n",
    "from helper.utils import signal_eff, get_optimal_threshold, convert_float64_to_float32, save_model, printmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=16\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows_b    = 200000\n",
    "nrows_udsg = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv('datasets/iter2/bjets_10-150GeV_base.csv', nrows=nrows_b)\n",
    "df_b['flavour'] = 'b'\n",
    "df_b = convert_float64_to_float32(df_b)\n",
    "# df_b.describe()\n",
    "# df_b['Jet_Pt'].describe([0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_udsg = pd.read_csv('datasets/iter2/udsgjets_10-150GeV_base.csv', nrows=nrows_udsg)\n",
    "df_udsg['flavour'] = 'udsg'\n",
    "df_udsg = convert_float64_to_float32(df_udsg)\n",
    "# df_udsg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_b, df_udsg])\n",
    "n_b_jets, n_udsg_jets = len(df_b), len(df_udsg)\n",
    "del df_b\n",
    "del df_udsg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\>\\> Select columns HERE (before logging data info) <<__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[col for col in df.columns if 'Jet_SecVtx_' not in col]]\n",
    "n_tracks, n_sv = 10, 3\n",
    "filter_tracks = lambda col: ('Jet_Track'  in col and int(col.split('_')[2]) < n_tracks)\n",
    "filter_sv     = lambda col: ('Jet_SecVtx' in col and int(col.split('_')[2]) < n_sv)\n",
    "filter_jet    = lambda col: ('Jet_Track'  not in col and 'Jet_SecVtx' not in col)\n",
    "filter_cols   = lambda col: filter_tracks(col) or filter_sv(col) or filter_jet(col)\n",
    "df = df[[col for col in df.columns if filter_cols(col)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subtract_phi(phi1, phi2):\n",
    "#     diff = phi1-phi2\n",
    "#     if abs(diff) <= np.pi: return diff\n",
    "#     elif diff > np.pi: return diff - 2*np.pi\n",
    "#     elif diff < -np.pi: return diff + 2*np.pi\n",
    "\n",
    "# def subtract_eta(eta1, eta2):\n",
    "#     diff = eta1-eta2\n",
    "#     return diff\n",
    "    \n",
    "# # for col in df.columns:\n",
    "# #     print(col)\n",
    "# #     if '_Phi__' in col:\n",
    "# #         df[col.replace('_Phi_', '_DeltaPhi_')] = df[[col, 'Jet_Phi']].apply(lambda row: subtract_phi(row[col], row['Jet_Phi']), axis=1)\n",
    "# #         df = df.drop(col, axis=1)\n",
    "# #     if  '_Eta__' in col:\n",
    "# #         df[col.replace('_Eta_', '_DeltaEta_')] = df[[col, 'Jet_Eta']].apply(lambda row: subtract_eta(row[col], row['Jet_Eta']), axis=1)\n",
    "# #         df = df.drop(col, axis=1)\n",
    "# #     if '_Pt__' in col:\n",
    "# #         df[col.replace('_Pt_', '_PtFrac_')] = df[[col, 'Jet_Pt']].apply(lambda row: row[col] / row['Jet_Pt'], axis=1)\n",
    "# #         df = df.drop(col, axis=1)     \n",
    "        \n",
    "# # for i_part in range(n_tracks):\n",
    "# #     print(i_part)\n",
    "# #     df[f'Jet_Track_{i_part}_DeltaR__sortby__IPdNsigma__desc']   = df[[f'Jet_Track_{i_part}_DeltaPhi__sortby__IPdNsigma__desc', f'Jet_Track_{i_part}_DeltaEta__sortby__IPdNsigma__desc']].apply(lambda row: np.sqrt(row[f'Jet_Track_{i_part}_DeltaPhi__sortby__IPdNsigma__desc']**2 + row[f'Jet_Track_{i_part}_DeltaEta__sortby__IPdNsigma__desc']**2), axis=1 )\n",
    "    \n",
    "\n",
    "# # for col in df.columns:\n",
    "# #     if 'IPd__' in col or 'IPz__' in col:\n",
    "# #         df = df.drop(col, axis=1)\n",
    "    \n",
    "# for i_part in range(n_tracks):\n",
    "#     print(i_part)\n",
    "#     df[f'Jet_Track_{i_part}_IPdNsigma__sortby__IPdNsigma__desc']   = df.apply(lambda row: row[f'Jet_Track_{i_part}_IPd__sortby__IPdNsigma__desc']/row[f'Jet_Track_{i_part}_CovIPd__sortby__IPdNsigma__desc'], axis=1 )\n",
    "#     df[f'Jet_Track_{i_part}_IPzNsigma__sortby__IPdNsigma__desc']   = df.apply(lambda row: row[f'Jet_Track_{i_part}_IPz__sortby__IPdNsigma__desc']/row[f'Jet_Track_{i_part}_CovIPz__sortby__IPdNsigma__desc'], axis=1 )\n",
    "#     df[f'Jet_Track_{i_part}_IP3dNsigma__sortby__IPdNsigma__desc']   = df.apply(lambda row: np.sqrt(row[f'Jet_Track_{i_part}_IPdNsigma__sortby__IPdNsigma__desc']**2 + row[f'Jet_Track_{i_part}_IPzNsigma__sortby__IPdNsigma__desc']**2), axis=1 )\n",
    "    \n",
    "    \n",
    "    \n",
    "# feats_descr = 'add Nsigma of IPd/IPz/IP3d '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset (DataFrame -> X & y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data using `stratify` with `flavour` and `Jet_Pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbins = np.array([df['Jet_Pt'].min()-1e-6] + [20, 30, 40, 50, 60, 70, 80, 90, 100] + [df['Jet_Pt'].max()+1e-6])\n",
    "flavour_ptbin = df[['flavour', 'Jet_Pt']].apply(lambda row: (row['flavour']+str(sum(row['Jet_Pt'] >= np.array(ptbins)))), axis=1)\n",
    "pt_bin_arr = df['Jet_Pt'].apply(lambda pt: str(sum(pt >= ptbins)))\n",
    "flavour_ptbin = df['flavour'] + pt_bin_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['flavour'].map({'b':1, 'udsg':0})\n",
    "X = df.drop(['flavour', 'ptbin'], axis=1)\n",
    "X_train, X_test, y_train, y_test, flavour_ptbin_train, flavour_ptbin_test = train_test_split(X, y, flavour_ptbin, test_size=0.2, stratify=flavour_ptbin, random_state=122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pt_spectra(pt_train, pt_test, bins=np.linspace(10,150,29), color='k', label='', ax=None):\n",
    "    density = 0\n",
    "    if not ax: \n",
    "        fig,ax = plt.subplots(figsize=(10,7))\n",
    "    ax.hist(pt_test    , bins=bins, histtype='step', lw=2, density=density, label='test '+label     , linestyle='-', color=color);\n",
    "    ax.hist(pt_train   , bins=bins, histtype='step', lw=2, density=density, label='train '+label    , linestyle='--', color=color);\n",
    "    ax.semilogy()\n",
    "    ax.legend();\n",
    "    ax.grid(linestyle=':')\n",
    "    ax.set_xlabel('jet $p_T^{reco}$ [GeV/c]')\n",
    "    ax.set_ylabel('counts')\n",
    "    return ax\n",
    "    \n",
    "ax = plot_pt_spectra(X_train['Jet_Pt'][y_train==1], X_test['Jet_Pt'][y_test==1], label='b', color='r')\n",
    "ax = plot_pt_spectra(X_train['Jet_Pt'][y_train==0], X_test['Jet_Pt'][y_test==0], label='udsg', color='b', ax=ax)\n",
    "# plt.savefig('pt_spect.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment and log data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    exp.end()\n",
    "except:\n",
    "    pass\n",
    "exp = Experiment(\n",
    "                 auto_output_logging='simple',\n",
    "                 log_env_gpu=False, log_env_cpu=False,\n",
    "                 project_name=\"default-setting-adjusting\", workspace=\"phd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.add_tags(['b-vs-light'])\n",
    "\n",
    "n_jets_str = f'there is:\\n\\t{n_b_jets} b jets\\n\\t{n_udsg_jets} udsg jets'\n",
    "dataset_info = n_jets_str + f'\\ndataframe size = {df.memory_usage(deep=True).sum()/1024/1024} MB'\n",
    "print(dataset_info)\n",
    "exp.log_dataset_info(dataset_info)\n",
    "exp.log_dataset_hash(df)\n",
    "exp.log_other('n_jets_b', n_b_jets)\n",
    "exp.log_other('n_jets_light', n_udsg_jets)\n",
    "exp.log_other('n_columns', X.shape[1])\n",
    "\n",
    "exp.log_parameter('n_tracks', n_tracks)\n",
    "exp.log_parameter('n_sv', n_sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter = 0\n",
    "\n",
    "def xgb_callback(y_pred, dtrain, mistag_rates=[0.1, 0.01, 0.001], make_plots=False):\n",
    "    global training_iter\n",
    "    y_true = dtrain.get_label()\n",
    "    metrics = []\n",
    "    for mistag_rate in mistag_rates:\n",
    "        metrics.append((f'bEff@mistag_{mistag_rate:.0e}', signal_eff(y_true, y_pred, mistag_rate)))\n",
    "    metrics.append(('ROC_AUC', roc_auc_score(y_true, y_pred)))\n",
    "    if any([' ' in met_name or ':' in met_name for met_name, _ in metrics]):\n",
    "        raise ValueError('Metric names cannot contain space nor colon(:)')\n",
    "\n",
    "    if not make_plots: \n",
    "        return metrics\n",
    "    is_testset = False\n",
    "    if len(y_true) == len(y_test):\n",
    "        is_testset = all(y_true == y_test)\n",
    "    if (not (training_iter % 20)) or training_iter in [0,1,3]:\n",
    "        if not is_testset:\n",
    "            ax = plot_tagging_eff(y_true, y_pred, label='train', color='r' if is_testset else 'b')\n",
    "        else:\n",
    "            ax = plot_tagging_eff(y_true, y_pred, label='test', color='r' if is_testset else 'b', ax=plt.gca())\n",
    "            ax.set_ylim(1e-4, 2)\n",
    "            exp.log_figure(f'plot_iter{training_iter:04}')        \n",
    "    if is_testset:\n",
    "        training_iter += 1        \n",
    "    return metrics\n",
    "\n",
    "\n",
    "params = dict(n_estimators=100, learning_rate=0.1, \n",
    "              max_depth=5, tree_method='exact', \n",
    "              subsample=0.8, colsample_bytree=0.8, colsample_bynode=0.8,\n",
    "              gamma=1, reg_lambda=1,\n",
    "              scale_pos_weight=(sum(y==0)/sum(y==1)), random_state=123,\n",
    "             )\n",
    "    \n",
    "exp.add_tag('XGB')\n",
    "exp.log_parameters(params, prefix='manual')\n",
    "clf = XGBClassifier(**params)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric=partial(xgb_callback, make_plots=True), verbose=10)\n",
    "# exp.send_notification(title='COMETML - test done', status='training finished', additional_data='No need of additional data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = clf.evals_result()\n",
    "for metric in eval_res['validation_0'].keys():\n",
    "    ax = plot_xgb_learning_curve(eval_res, metric)\n",
    "    exp.log_figure(f'{metric}_vs_ntrees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf, X.columns, exp, 'xgb_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "opt_thresh = get_optimal_threshold(y_train, y_train_proba, 0.03)\n",
    "y_train_pred_opt = (y_train_proba > opt_thresh).astype('int')\n",
    "y_test_pred_opt  = (y_test_proba  > opt_thresh).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=2, figsize=(12,7), gridspec_kw={'height_ratios': [2,1]})\n",
    "plot_score_distr(y_train, y_train_proba, linestyle=':', ax=axes[0])\n",
    "plot_score_distr(y_test , y_test_proba , linestyle='-', ax=axes[0], lw=2)\n",
    "plot_signal_significance(y_train, y_train_proba, 0.01,    linestyle=':', color='cyan'   ,  label='b frac. = 1%', ax=axes[1])\n",
    "plot_signal_significance(y_train, y_train_proba, 0.03,    linestyle=':', color='lime'   ,  label='b frac. = 3%', ax=axes[1])\n",
    "plot_signal_significance(y_train, y_train_proba, 0.04,    linestyle=':', color='magenta',  label='b frac. = 4%', ax=axes[1])\n",
    "# plot_signal_significance(y_test , y_test_proba , 0.01,    linestyle='-', color='lime'   , lw=2, label='b frac. = 1%', ax=axes[1])\n",
    "# plot_signal_significance(y_test , y_test_proba , 0.04,    linestyle='-', color='magenta', lw=2, label='b frac. = 4%', ax=axes[1])\n",
    "axes[0].vlines(opt_thresh, *axes[0].get_ylim(), color='lime', lw=2, linestyle=':')\n",
    "exp.log_figure('score_and_significance_vs_threshold')\n",
    "\n",
    "xmax = max(max(y_train_proba), max(y_test_proba))\n",
    "axes[0].set_xlim(xmax-0.2, xmax+0.01)\n",
    "axes[1].set_xlim(xmax-0.2, xmax+0.01)\n",
    "axes[1].set_ylim(0.95,1)\n",
    "exp.log_figure('score_and_significance_vs_threshold_zoom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC - log AUC scores and plot vs pT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_roc(y_train, y_train_proba, label='train', color='b');\n",
    "ax = plot_roc(y_test, y_test_proba, label='test' , color='r', ax=ax);\n",
    "exp.log_figure('roc_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.log_metric('roc_auc_test', roc_auc_score(y_test, y_test_proba))\n",
    "exp.log_metric('roc_auc_train', roc_auc_score(y_train, y_train_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_score_vs_pt(y_train, y_train_pred, y_train_proba, flavour_ptbin_train, ptbins, score=(roc_auc_score, 'ROC AUC'), label='train', marker='o', color='b')\n",
    "ax = plot_score_vs_pt(y_test, y_test_pred, y_test_proba, flavour_ptbin_test , ptbins, score=(roc_auc_score, 'ROC AUC'), label='test' , marker='^', color='r', ax=ax)\n",
    "exp.log_figure('roc_auc_vs_pt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mistagging rate VS _b_ tagging efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_tagging_eff(y_test, y_test_proba, label='$b$ vs $udsg$ test', color='r')\n",
    "plot_tagging_eff(y_train, y_train_proba, label='$b$ vs $udsg$ train', color='b', ax=ax)\n",
    "exp.log_figure('tagging_eff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistag_rates = [0.1, 0.01, 0.001]\n",
    "for mistag_rate in mistag_rates:\n",
    "    eff = signal_eff(y_test, y_test_proba, mistag_rate)\n",
    "    exp.log_metric(f'bEff@mistag_{mistag_rate:.0e}', eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('__TRAIN__')\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plot_confusion_matrix(y_train, y_train_pred_opt, ['udsg', 'b'], title='train, unnormalized', normalize=False, ax=axes[0])\n",
    "plot_confusion_matrix(y_train, y_train_pred_opt, ['udsg', 'b'], title='train, normalized'  , normalize=True , ax=axes[1])\n",
    "exp.log_figure('confusion_matrix_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('__TEST__')\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plot_confusion_matrix(y_test, y_test_pred_opt, ['udsg', 'b'], title='test, unnormalized', normalize=False, ax=axes[0])\n",
    "plot_confusion_matrix(y_test, y_test_pred_opt, ['udsg', 'b'], title='test, normalized'  , normalize=True , ax=axes[1])\n",
    "exp.log_figure('confusion_matrix_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat_imp, feat_name in sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), X.columns), reverse=True):\n",
    "    print(feat_name, feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
