{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/eos/user/s/sbysiak/.local/lib/python3.7/site-packages/\")\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 0.22 needed for permutation importance\n",
    "import sys\n",
    "sys.path.insert(0, \"/eos/user/s/sbysiak/.local/lib/python3.7/site-packages/\")\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.preprocessing import add_sorting_index, add_sorted_col, add_nth_val, apply_cut\n",
    "from helper.utils import convert_float64_to_float32\n",
    "\n",
    "from helper.plotting import plot_roc, plot_score_vs_pt, plot_score_vs_col, plot_tagging_eff, plot_confusion_matrix, plot_xgb_learning_curve, plot_score_distr, plot_signal_significance, plot_eff_vs_threshold, plot_pdp\n",
    "from helper.utils import signal_eff, get_optimal_threshold, convert_float64_to_float32, save_model, printmd\n",
    "from helper.interpret import feature_importance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=16\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare DMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate available #jets and decide trainset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round_down(x,n=2):\n",
    "#     return np.floor(x*10**n)/10**n\n",
    "\n",
    "# # round_down(123.999, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_name_core = 'JetTree_AliAnalysisTaskJetExtractor_Jet_AKTChargedR040_tracks_pT0150_E_scheme_'\n",
    "data_dir = '../ana_results/iter3/LHC16h3/'\n",
    "files = [os.path.join(data_dir, d, 'AnalysisResults.root') for d in os.listdir(data_dir)]\n",
    "\n",
    "\n",
    "def calc_njets(files, n_b=None, trainset_frac_b=None):\n",
    "    if n_b and trainset_frac_b:\n",
    "        raise ValueError('One cannot provide both parameters: `n_b` and `trainset_frac_b`')\n",
    "    if not n_b and not trainset_frac_b:\n",
    "        raise ValueError('Provide on out of these two parameters: `n_b` and `trainset_frac_b`')\n",
    "        \n",
    "    n_avail_b, n_avail_c, n_avail_udsg = 0, 0, 0\n",
    "    for f in files:\n",
    "        froot = uproot.open(f)\n",
    "        n_avail_b += froot[tree_name_core+'bJets'].numentries\n",
    "        n_avail_c += froot[tree_name_core+'cJets'].numentries\n",
    "        n_avail_udsg += froot[tree_name_core+'udsgJets'].numentries\n",
    "#     print(n_avail_b, n_avail_c, n_avail_udsg)\n",
    "\n",
    "    if not n_b:\n",
    "        n_b = int(n_avail_b * trainset_frac_b)\n",
    "    else:\n",
    "        trainset_frac_b = n_b / n_avail_b # round_down(n_b / n_avail_b, 4)\n",
    "    n_c    = int(0.1 * n_b)\n",
    "    n_udsg = int(0.9 * n_b)\n",
    "\n",
    "    trainset_frac_c    = n_c / n_avail_c # round_down(n_c / n_avail_c, 4)\n",
    "    trainset_frac_udsg = n_udsg / n_avail_udsg # round_down(n_udsg / n_avail_udsg, 4)\n",
    "    \n",
    "    d = {'b'   :[n_avail_b, n_b, trainset_frac_b], \n",
    "         'c'   :[n_avail_c, n_c, trainset_frac_c], \n",
    "         'udsg':[n_avail_udsg, n_udsg, trainset_frac_udsg]}\n",
    "    df = pd.DataFrame(d)\n",
    "    df.index = ['n available', 'n trainset', 'trainset fraction']\n",
    "    return df\n",
    "    \n",
    "    \n",
    "n_jets = calc_njets(files, trainset_frac_b=0.5)\n",
    "n_jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jets.loc['trainset fraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROOT->CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "\n",
    "#     def IPdNSigmaAbs_cutSmallSigma(row):\n",
    "#         pt = row['Jet_Track_Pt']\n",
    "#         IPd_sigma = np.sqrt(row['Jet_Track_CovIPd'])\n",
    "#         sigma_threshold = 0.004444561*pt**(-0.4790711) if pt < 10 else 0.0016\n",
    "#         if IPd_sigma > sigma_threshold:\n",
    "#             return abs(row['Jet_Track_IPd'] / IPd_sigma)\n",
    "#         else:\n",
    "#             return -1\n",
    "    \n",
    "    \n",
    "    def subtract_phi(phi1, phi2):\n",
    "        diff = phi1-phi2\n",
    "        if abs(diff) <= np.pi: return diff\n",
    "        elif diff > np.pi: return diff - 2*np.pi\n",
    "        elif diff < -np.pi: return diff + 2*np.pi\n",
    "\n",
    "\n",
    "    def subtract_eta(eta1, eta2):\n",
    "        diff = eta1-eta2\n",
    "        return diff\n",
    "    \n",
    "    # add custom features\n",
    "#     df['Jet_Track_DeltaPhi'] = df.apply(lambda row: np.array([ subtract_phi(tr_phi, row['Jet_Phi']) for tr_phi in row['Jet_Track_Phi']]), axis=1)\n",
    "#     df['Jet_Track_DeltaEta'] = df.apply(lambda row: np.array([ subtract_eta(tr_eta, row['Jet_Eta']) for tr_eta in row['Jet_Track_Eta']]), axis=1)\n",
    "#     df['Jet_Track_DeltaR']   = df.apply(lambda row: np.array([ np.sqrt(tr_phi**2 + tr_eta**2)       for tr_phi, tr_eta in zip(row['Jet_Track_DeltaPhi'], row['Jet_Track_DeltaEta'])]), axis=1)\n",
    "#     df['Jet_Track_PtFrac']   = df.apply(lambda row: np.array([ (tr_pt/row['Jet_Pt'])                for tr_pt in row['Jet_Track_Pt']]), axis=1)\n",
    "#     df = df.drop(['Jet_Track_Phi', 'Jet_Track_Eta'])\n",
    "# IPdNsigma, IPzNsigma, IP3dNsigma\n",
    "# \n",
    "\n",
    "#     df['Jet_Track_IPdNsigmaAbs']  = df.apply(lambda row: abs(row['Jet_Track_IPd'] / np.sqrt(row['Jet_Track_CovIPd'])), axis=1)\n",
    "#     df['Jet_Track_IPdNsigmaAbs']  = df.apply(lambda row: IPdNsigmaAbs_cutSmallSigma(row), axis=1)\n",
    "    df['Jet_Track_IPdSigma']  = df['Jet_Track_CovIPd'].pow(0.5)\n",
    "    df['Jet_Track_IPzSigma']  = df['Jet_Track_CovIPz'].pow(0.5)\n",
    "    df = df.drop(['Jet_Track_CovIPd', 'Jet_Track_CovIPz'], axis=1)\n",
    "    \n",
    "    df['Jet_Track_IPdAbs']          = eval('abs(a)', dict(a=df['Jet_Track_IPd'])) \n",
    "    df['Jet_Track_IPzAbs']          = eval('abs(a)', dict(a=df['Jet_Track_IPz'])) \n",
    "    df['Jet_Track_IPdNsigma']       = eval('a/b', dict(a=df['Jet_Track_IPd'], b=df['Jet_Track_IPdSigma'])) \n",
    "    df['Jet_Track_IPzNsigma']       = eval('a/b', dict(a=df['Jet_Track_IPz'], b=df['Jet_Track_IPzSigma'])) \n",
    "    df['Jet_Track_IPdNsigmaAbs']    = eval('abs(a)/b', dict(a=df['Jet_Track_IPd'], b=df['Jet_Track_IPdSigma'])) \n",
    "    df['Jet_Track_IPzNsigmaAbs']    = eval('abs(a)/b', dict(a=df['Jet_Track_IPz'], b=df['Jet_Track_IPzSigma'])) \n",
    "\n",
    "#     def cut_val(track_pt):\n",
    "#         return 0.004444561*track_pt**(-0.4790711) if track_pt < 10 else 0.0015\n",
    "    \n",
    "#     df['Jet_Track_CutIPdSigmaVSPt'] = df.apply(lambda row: \n",
    "#                                         np.array([int(ipd_sigma < cut_val(pt))  for ipd_sigma, pt in zip(row['Jet_Track_IPdSigma'], row['Jet_Track_Pt'])]),\n",
    "#                                         axis=1\n",
    "#                                       )\n",
    "#     df = df.drop(['Jet_Track_IPd', ], axis=1)\n",
    "#     df = df.drop(['Jet_Track_IPd', 'Jet_Track_IPz'], axis=1)\n",
    "    \n",
    "    df['Jet_SecVtx_LxyNsigma'] = eval('a / b', dict(a=df['Jet_SecVtx_Lxy'], b=df['Jet_SecVtx_SigmaLxy']))\n",
    "    \n",
    "    ### create index cols\n",
    "    track_sorting_var = 'IPdNsigmaAbs'\n",
    "    sv_sorting_var    = 'LxyNsigma'\n",
    "    add_sorting_index(df, f'Jet_Track_{track_sorting_var}', 'desc')\n",
    "    add_sorting_index(df, f'Jet_SecVtx_{sv_sorting_var}', 'desc')\n",
    "\n",
    "    ### apply cuts a.k.a. filter index cols\n",
    "#     apply_cut(df, 'Jet_Track_IPdNsigmaAbs < 50', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_Track_Pt > 0.5', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_Track_CutIPdSigmaVSPt < 0.5', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_Chi2 < 10' ,'LxyNsigma', 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_Dispersion < 0.01' ,'LxyNsigma', 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_SigmaLxy < 0.1' ,'LxyNsigma', 'desc')\n",
    "    \n",
    "    ### create sorted cols\n",
    "    track_params = ['Jet_Track_Pt', 'Jet_Track_Phi', 'Jet_Track_Eta', \n",
    "                    'Jet_Track_DeltaPhi', 'Jet_Track_DeltaEta', 'Jet_Track_PtFrac', 'Jet_Track_DeltaR',\n",
    "                    'Jet_Track_Charge', 'Jet_Track_Label', \n",
    "                    'Jet_Track_IPd', 'Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz', \n",
    "                    'Jet_Track_ProdVtx_X', 'Jet_Track_ProdVtx_Y', 'Jet_Track_ProdVtx_Z',\n",
    "                   \n",
    "                    'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', \n",
    "                    'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth',\n",
    "                    \n",
    "                    'Jet_Track_IPdAbs'      , 'Jet_Track_IPzAbs',\n",
    "                    'Jet_Track_IPdSigma'    , 'Jet_Track_IPzSigma',\n",
    "                    'Jet_Track_IPdNsigma'   , 'Jet_Track_IPzNsigma',  \n",
    "                    'Jet_Track_IPdNsigmaAbs', 'Jet_Track_IPzNsigmaAbs',\n",
    "                   ]\n",
    "    \n",
    "    sv_params    = ['Jet_SecVtx_X', 'Jet_SecVtx_Y', 'Jet_SecVtx_Z', \n",
    "                    'Jet_SecVtx_Mass', \n",
    "                    'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion', 'Jet_SecVtx_LxyNsigma',\n",
    "                   ]\n",
    "    \n",
    "    track_params = [par for par in track_params if par in df.columns]\n",
    "    sv_params    = [par for par in  sv_params   if par in df.columns]\n",
    "\n",
    "    for param in track_params:\n",
    "        add_sorted_col(df, param ,   track_sorting_var, 'desc')\n",
    "\n",
    "    for param in sv_params:\n",
    "        add_sorted_col(df, param ,   sv_sorting_var, 'desc')\n",
    "\n",
    "    \n",
    "    ### extract n-th value from sorted cols\n",
    "#     new_training_cols = []\n",
    "    n_tracks, n_sv = 10,3\n",
    "    for param in track_params:\n",
    "        for i in range(n_tracks):\n",
    "            add_nth_val(df, col_name=f'{param}__sortby__{track_sorting_var}__desc', n=i, fillna=None)\n",
    "#             new_training_cols.append(df.columns[-1])\n",
    "\n",
    "    for param in sv_params:\n",
    "        for i in range(n_sv):\n",
    "            add_nth_val(df, col_name=f'{param}__sortby__{sv_sorting_var}__desc', n=i, fillna=None)\n",
    "#             new_training_cols.append(df.columns[-1])\n",
    "\n",
    "    ### drop temporary columns, i.e. those containing arrays, like 'Index__*' as well as initial columns used for extraction, like 'Jet_Track_Pt'\n",
    "#     columns_to_keep = df.select_dtypes(exclude=['object']).columns\n",
    "    columns_to_keep = [col for col,val in zip(df.columns, df.iloc[0]) if not hasattr(val, '__iter__') or isinstance(val, str)]\n",
    "    return df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_to_read = ['Jet_Pt', \n",
    "                 'Jet_Phi', 'Jet_Eta', \n",
    "                 'Jet_Area', 'Jet_NumTracks',\n",
    "#                  'Jet_Track_Pt', \n",
    "#                  'Jet_Track_Phi', 'Jet_Track_Eta', \n",
    "                 'Jet_Track_IPd','Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz',\n",
    "#             'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', 'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth',\n",
    "            'Jet_SecVtx_Mass', 'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion',\n",
    "\n",
    "#             'Jet_Shape_Mass_NoCorr', 'Jet_Shape_Mass_DerivCorr_1', 'Jet_Shape_Mass_DerivCorr_2',\n",
    "#             'Jet_Shape_pTD_DerivCorr_1', 'Jet_Shape_pTD_DerivCorr_2', 'Jet_Shape_LeSub_NoCorr', 'Jet_Shape_LeSub_DerivCorr',\n",
    "#             'Jet_Shape_Angularity', 'Jet_Shape_Angularity_DerivCorr_1', 'Jet_Shape_Angularity_DerivCorr_2',\n",
    "#             'Jet_Shape_Circularity_DerivCorr_1', 'Jet_Shape_Circularity_DerivCorr_2', 'Jet_Shape_Sigma2_DerivCorr_1', 'Jet_Shape_Sigma2_DerivCorr_2',\n",
    "#             'Jet_Shape_NumTracks_DerivCorr', 'Jet_Shape_MomentumDispersion', 'Jet_Shape_TrackPtMean', 'Jet_Shape_TrackPtMedian',\n",
    "                ]\n",
    "\n",
    "froot = uproot.open(os.path.join('../ana_results/iter3/LHC16h3/ptbin1/AnalysisResults.root'))\n",
    "df = froot[tree_name_core+'bJets'].pandas.df(flatten=False, branches=branches_to_read)#.query('Jet_Pt > 10 and Jet_Pt < 100')\n",
    "print('tree reading done')\n",
    "df_after = add_features(df)\n",
    "print('features extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jets = calc_njets(files, n_b=2000000)\n",
    "n_jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b = froot[tree_name_core+'bJets'].pandas.df(flatten=False, branches=branches_to_read, entrystart=istart, entrystop=istop).query(query_str)\n",
    "#             if len(df) < 2: continue\n",
    "#             df = convert_float64_to_float32(df)\n",
    "#             df = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp_key = ''.join(np.random.choice([l for l in 'abcdefghijklmnopqrstuvwxyz1234567890'], 6))\n",
    "n_jets.to_csv(f'n_jets_{data_tmp_key}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = n_jets.loc['trainset fraction']\n",
    "n_chunk = 10000\n",
    "fname = f'train_{data_temp_key}.csv'\n",
    "flavour_map = {'b':1, 'c':0, 'udsg':0}\n",
    "offset = 0\n",
    "\n",
    "open(fname, 'w').close() # clear file\n",
    "\n",
    "is_first = True\n",
    "for f in files:\n",
    "    froot = uproot.open(f)\n",
    "    tic = time()\n",
    "    for flavour in ['b', 'c', 'udsg']:\n",
    "        n_avail = froot[tree_name_core+f'{flavour}Jets'].numentries\n",
    "        n_read = int(n_avail * fractions[flavour])\n",
    "        print(f'Reading {n_read:6d} {flavour:>4s}-jets from {f}')\n",
    "        for i in range(int(n_read/n_chunk)+1):\n",
    "            istart = i*n_chunk + offset\n",
    "            istop = min((i+1)*n_chunk, n_read) + offset\n",
    "#             print(f'\\t\\t\\t {istart:7d} -- {istop:7d}')\n",
    "            df = froot[tree_name_core+f'{flavour}Jets'].pandas.df(flatten=False, branches=branches_to_read, entrystart=istart, entrystop=istop)\n",
    "            if len(df) < 2: continue\n",
    "            df = convert_float64_to_float32(df)\n",
    "            df = add_features(df)\n",
    "            df.insert(loc=0, column='label', value=flavour_map[flavour])\n",
    "            df.to_csv(fname, mode='a', index=False, header=is_first)\n",
    "            is_first=False\n",
    "    print(f'\\t\\t{f} processed in {time()-tic:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = n_jets.loc['trainset fraction']\n",
    "n_chunk = 10000\n",
    "fname = f'test_{data_temp_key}.csv'\n",
    "flavour_map = {'b':1, 'c':0, 'udsg':0}\n",
    "\n",
    "open(fname, 'w').close() # clear file\n",
    "\n",
    "is_first = True\n",
    "for f in files:\n",
    "    tic = time()\n",
    "    froot = uproot.open(f)\n",
    "    for flavour in ['b', 'c', 'udsg']:\n",
    "        n_avail = froot[tree_name_core+f'{flavour}Jets'].numentries\n",
    "        offset = int(n_avail * fractions[flavour])\n",
    "        n_read = int(n_avail * fractions[flavour]/5)\n",
    "        print(f'Reading {n_read:6d} {flavour:>4s}-jets from {f}')\n",
    "        for i in range(int(n_read/n_chunk)+1):\n",
    "            istart = i*n_chunk + offset\n",
    "            istop = min((i+1)*n_chunk, n_read) + offset\n",
    "#             print(f'\\t\\t\\t {istart:7d} -- {istop:7d}')\n",
    "            df = froot[tree_name_core+f'{flavour}Jets'].pandas.df(flatten=False, branches=branches_to_read, entrystart=istart, entrystop=istop)\n",
    "            if len(df) < 2: continue\n",
    "            df = convert_float64_to_float32(df)\n",
    "            df = add_features(df)\n",
    "            df.insert(loc=0, column='label', value=flavour_map[flavour])\n",
    "            df.to_csv(fname, mode='a', index=False, header=is_first)\n",
    "            is_first=False\n",
    "    print(f'\\t\\t{f} processed in {time()-tic:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV->DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'train_2M-b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in pd.read_csv(fname, nrows=1).columns if '0' in c or 'Track' not in c and 'SecVtx' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in df.columns if 'Track_0_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm tmp/dtrain.cache tmp/dtest.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(f'{fname}?format=csv&label_column=0#tmp/dtrain.cache')\n",
    "# l = dtrain.num_row()\n",
    "# idx = [i for i in range(0,l,10)]\n",
    "# dtrain = dtrain.slice(idx)\n",
    "dtest = xgb.DMatrix(f'{fname.replace(\"train\",\"test\")}?format=csv&label_column=0#tmp/dtest.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = dtrain_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train-validation split (if there is one csv file available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain_eval = dtrain\n",
    "val_frac = 0.1\n",
    "n = dtrain_val.num_row()\n",
    "val_idx = np.random.choice(n, size=int(val_frac*n), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIGHLY INEFFECTIVE\n",
    "train_idx = [i for i in np.arange(n) if i not in val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx), len(train_idx), dtrain_val.num_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval, dtrain = dtrain_val.slice(val_idx), dtrain_val.slice(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create experiment and log data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user --no-cache-dir --upgrade comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    exp.end()\n",
    "except:\n",
    "    pass\n",
    "exp = Experiment(\n",
    "                 auto_output_logging='simple',\n",
    "                 log_env_gpu=False, log_env_cpu=False,\n",
    "                 project_name=\"test\", workspace=\"phd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv(fname, nrows=1).columns\n",
    "print(columns.to_list())\n",
    "print('\\n\\n')\n",
    "for c in [col for col in columns if ('Jet_Track_' not in col and 'Jet_SecVtx_' not in col) or '0' in col]: print(c)\n",
    "n_tracks = max([int(col.split('_')[2]) for col in columns if 'Jet_Track_' in col])+1\n",
    "n_sv     = max([int(col.split('_')[2]) for col in columns if 'Jet_SecVtx' in col])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtrain.get_label()\n",
    "print(f'train set: b: {sum(y==1)}, rest: {sum(y==0)}')\n",
    "yv = dval.get_label()\n",
    "print(f'valid set: b: {sum(yv==1)}, rest: {sum(yv==0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.add_tags(['b-vs-rest'])\n",
    "# if nrows_c == nrows_udsg: exp.add_tag('N_c = N_udsg')\n",
    "# else: exp.add_tag('N_c =/= N_udsg')\n",
    "\n",
    "y = dtrain.get_label()\n",
    "exp.log_other('n_jets_b', sum(y==1))\n",
    "exp.log_other('n_jets_rest', sum(y==0))\n",
    "# exp.log_other('n_jets_c', n_c_jets)\n",
    "# exp.log_other('n_jets_udsg', n_udsg_jets)\n",
    "\n",
    "exp.log_other('n_columns', dtrain.num_col())\n",
    "exp.log_other('n_rows', dtrain.num_row())\n",
    "exp.log_other('n_jets', dtrain.num_row())\n",
    "exp.log_parameter('n_tracks', n_tracks)\n",
    "exp.log_parameter('n_sv', n_sv)\n",
    "\n",
    "# n_jets_str = f'there is:\\n\\t{n_b_jets} b jets\\n\\t{n_c_jets} c jets\\n\\t{n_udsg_jets} udsg jets'\n",
    "dataset_info = f'ncols={dtrain.num_col()}, nrows={dtrain.num_row()}, ntr={n_tracks}, nsv={n_sv}'\n",
    "print(dataset_info)\n",
    "exp.log_dataset_info(dataset_info)\n",
    "exp.log_dataset_hash(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.add_tag('full-info')\n",
    "# custom_descr = '2M-b, perf, overfit3X: lr=0.5, depth=15, n_est=10\n",
    "custom_descrtom_descr = 'DUMMY'\n",
    "exp.log_other('descr', f'{custom_descr} ; {dataset_info}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance of XGBClassifier trained on pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b = pd.read_csv('datasets/iter2/bjets_10-150GeV_Tr-sortbyIPdNsigmaAbs-noCuts_SV-sortbyLxyNsigma-noCuts.csv', nrows=50000)\n",
    "# df_udsg = pd.read_csv('datasets/iter2/udsgjets_10-150GeV_Tr-sortbyIPdNsigmaAbs-noCuts_SV-sortbyLxyNsigma-noCuts.csv', nrows=50000)\n",
    "# df_b['label'] = 1\n",
    "# df_udsg['label'] = 0\n",
    "# df = pd.concat([df_b, df_udsg], axis=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = pd.read_csv(fname)\n",
    "# print(fname)\n",
    "# df = pd.read_csv(fname)\n",
    "# y = df['label']\n",
    "# X = df.drop('label', axis=1)\n",
    "# if 'ptbin' in X.columns: X = X.drop('ptbin', axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = dict(n_estimators=2, learning_rate=0.2, \n",
    "#               max_depth=5, tree_method='exact', \n",
    "#               gamma=10, reg_lambda=0,\n",
    "#               subsample=0.8, colsample_bytree=0.8, colsample_bynode=0.8,\n",
    "#               scale_pos_weight=(sum(y==0)/sum(y==1)), random_state=123,\n",
    "#              )\n",
    "    \n",
    "# # exp.add_tag('XGB')\n",
    "# # exp.log_parameters(params, prefix='manual')  # backward compatibility\n",
    "# # exp.log_parameters(params, prefix='man')\n",
    "# clf = XGBClassifier(**params)\n",
    "# clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "# #         eval_metric=partial(xgb_callback, make_plots=True), \n",
    "#         verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "# y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# print('roc_auc_test', roc_auc_score(y_test, y_test_proba))\n",
    "# print('roc_auc_train', roc_auc_score(y_train, y_train_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter = 0\n",
    "\n",
    "y_train = dtrain.get_label()\n",
    "y_test = dtest.get_label()\n",
    "\n",
    "\n",
    "\n",
    "def xgb_callback(y_pred, dtrain, mistag_rates=[0.1, 0.01, 0.001], make_plots=False):\n",
    "    global training_iter\n",
    "    y_true = dtrain.get_label()\n",
    "    metrics = []\n",
    "    for mistag_rate in mistag_rates:\n",
    "        metrics.append((f'bEff@mistag_{mistag_rate:.0e}', signal_eff(y_true, y_pred, mistag_rate)))\n",
    "#     metrics.append(('ROC_AUC', roc_auc_score(y_true, y_pred)))\n",
    "    if any([' ' in met_name or ':' in met_name for met_name, _ in metrics]):\n",
    "        raise ValueError('Metric names cannot contain space nor colon(:)')\n",
    "\n",
    "    if not make_plots: \n",
    "        return metrics\n",
    "    is_testset = False\n",
    "    if len(y_true) == len(y_test):\n",
    "        is_testset = all(y_true == y_test)\n",
    "    if (not (training_iter % 30)) or training_iter in [0,1,3]:\n",
    "        if not is_testset:\n",
    "            ax = plot_tagging_eff(y_true, y_pred, label='train', color='r' if is_testset else 'b')\n",
    "        else:\n",
    "            ax = plot_tagging_eff(y_true, y_pred, label='test', color='r' if is_testset else 'b', ax=plt.gca())\n",
    "            ax.set_ylim(1e-4, 2)\n",
    "            exp.log_figure(f'plot_iter{training_iter:04}')        \n",
    "    if is_testset:\n",
    "        training_iter += 1        \n",
    "    return metrics\n",
    "\n",
    "\n",
    "params = dict(objective='binary:logistic',\n",
    "              n_estimators=100,\n",
    "              learning_rate=0.1, \n",
    "              max_depth=15, tree_method='approx', \n",
    "              min_split_loss=10, reg_lambda=0, # aka gamma, L2\n",
    "              subsample=0.8, colsample_bytree=1, colsample_bynode=1,\n",
    "              scale_pos_weight=sum(y==0)/sum(y==1), \n",
    "#               random_state=123,\n",
    "              eval_metric=['auc', 'logloss', ]\n",
    "             )\n",
    "    \n",
    "exp.add_tag('XGB')\n",
    "exp.log_parameters(params, prefix='manual')  # backward compatibility\n",
    "exp.log_parameters(params, prefix='man')\n",
    "\n",
    "watchlist = [(dtrain, 'train'),(dval, 'eval'),]\n",
    "eval_res = {}\n",
    "\n",
    "tic = time()\n",
    "bst = xgb.train(params, dtrain, params['n_estimators'], \n",
    "                watchlist, evals_result=eval_res, \n",
    "                feval=partial(xgb_callback, make_plots=True))\n",
    "\n",
    "exp.log_other('training time', int(time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('tmp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_res = clf.evals_result()\n",
    "for metric in eval_res[list(eval_res.keys())[0]].keys():\n",
    "    print(metric)\n",
    "    ax = plot_xgb_learning_curve(eval_res, metric)\n",
    "    exp.log_figure(f'{metric}_vs_ntrees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(clf, X.columns, scaler, exp, 'xgb_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- **saving & loading**\n",
    "    - requires: booster.save_model(), list of input files, fractions, add_features() func, (list of columns), ...\n",
    "    - should work with:   \n",
    "        1) dynamically reading from ROOT  \n",
    "        2) from ready csv -- such file has to have all required fields associated with it, e.g. zipped\n",
    "- learning curves  -- DONE\n",
    "- reading dataframes from CSV -- DONE\n",
    "- callbacks -- plots & logging of -- DONE\n",
    "- pT-weighted test set (at least assign weights and pass when logging metrics: auc and signal eff)  \n",
    "  check how many splittings come from low pt jets, in given Erad bins\n",
    "- investigate differences in pT between train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report performance -- _bulk_  (based on just scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dtrain.get_label()\n",
    "y_train_proba = bst.predict(dtrain)\n",
    "\n",
    "y_test = dtest.get_label()\n",
    "y_test_proba = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_thresh = get_optimal_threshold(y_train, y_train_proba, 0.04)\n",
    "y_train_pred_opt = (y_train_proba > opt_thresh).astype('int')\n",
    "y_test_pred_opt  = (y_test_proba  > opt_thresh).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistag_rates = [0.1, 0.01, 0.001]\n",
    "for mistag_rate in mistag_rates:\n",
    "    eff = signal_eff(y_test, y_test_proba, mistag_rate)\n",
    "    exp.log_metric(f'tagEff@mistag_{mistag_rate:.0e}', eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # raise NotImplementedError('TODO')\n",
    "fig,axes = plt.subplots(nrows=2, figsize=(12,7), gridspec_kw={'height_ratios': [2,1]})\n",
    "plot_score_distr(y_train, y_train_proba, linestyle=':', ax=axes[0])\n",
    "plot_score_distr(y_test , y_test_proba , linestyle='-', ax=axes[0], lw=2)\n",
    "plot_signal_significance(y_train, y_train_proba, 0.02,    linestyle=':', color='cyan'   ,  label='b frac. = 2%', ax=axes[1])\n",
    "plot_signal_significance(y_train, y_train_proba, 0.04,    linestyle=':', color='lime'   ,  label='b frac. = 4%', ax=axes[1])\n",
    "plot_signal_significance(y_train, y_train_proba, 0.08,    linestyle=':', color='magenta',  label='b frac. = 8%', ax=axes[1])\n",
    "# plot_signal_significance(y_test , y_test_proba , 0.01,    linestyle='-', color='lime'   , lw=2, label='b frac. = 1%', ax=axes[1])\n",
    "# plot_signal_significance(y_test , y_test_proba , 0.04,    linestyle='-', color='magenta', lw=2, label='b frac. = 4%', ax=axes[1])\n",
    "axes[0].vlines(opt_thresh, *axes[0].get_ylim(), color='lime', lw=2, linestyle=':')\n",
    "exp.log_figure('score_and_significance_vs_threshold')\n",
    "\n",
    "xmax = max(max(y_train_proba), max(y_test_proba))\n",
    "axes[0].set_xlim(xmax-0.2, xmax+0.01)\n",
    "axes[1].set_xlim(xmax-0.2, xmax+0.01)\n",
    "axes[1].set_ylim(0.95,1)\n",
    "exp.log_figure('score_and_significance_vs_threshold_zoom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eff vs threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_eff_vs_threshold(y_test, y_test_proba)\n",
    "exp.log_figure('eff_vs_threshold')\n",
    "ax.set_xlim(0.6,1)\n",
    "exp.log_figure('eff_vs_threshold_zoom')\n",
    "ax.set_yscale('log')\n",
    "exp.log_figure('eff_vs_threshold_logy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC - log AUC scores and plot vs pT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_roc(y_train, y_train_proba, label='train', color='b');\n",
    "ax = plot_roc(y_test, y_test_proba, label='test' , color='r', ax=ax);\n",
    "exp.log_figure('roc_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.log_metric('roc_auc_test', roc_auc_score(y_test, y_test_proba))\n",
    "exp.log_metric('roc_auc_train', roc_auc_score(y_train, y_train_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mistagging rate VS tagging efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_tagging_eff(y_test, y_test_proba, label='$b$ vs $c+udsg$ test', color='r')\n",
    "plot_tagging_eff(y_train, y_train_proba, label='$b$ vs $c+udsg$ train', color='b', ax=ax)\n",
    "exp.log_figure('tagging_eff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistag_rates = [0.1, 0.01, 0.001]\n",
    "for mistag_rate in mistag_rates:\n",
    "    eff = signal_eff(y_test, y_test_proba, mistag_rate)\n",
    "    exp.log_metric(f'tagEff@mistag_{mistag_rate:.0e}', eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('__TRAIN__')\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plot_confusion_matrix(y_train, y_train_pred_opt, ['c+udsg', 'b'], title='train, unnormalized', normalize=False, ax=axes[0])\n",
    "plot_confusion_matrix(y_train, y_train_pred_opt, ['c+udsg', 'b'], title='train, normalized'  , normalize=True , ax=axes[1])\n",
    "exp.log_figure('confusion_matrix_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('__TEST__')\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plot_confusion_matrix(y_test, y_test_pred_opt, ['c+udsg', 'b'], title='test, unnormalized', normalize=False, ax=axes[0])\n",
    "plot_confusion_matrix(y_test, y_test_pred_opt, ['c+udsg', 'b'], title='test, normalized'  , normalize=True , ax=axes[1])\n",
    "exp.log_figure('confusion_matrix_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report performance -- _bulk_ on $p_T$-weigthed scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report performance -- _differential_  (based on full dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_train, y_test, y_train_proba, y_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.load_model('tmp.model')\n",
    "clf.classes_ = np.array([0,1])\n",
    "\n",
    "# https://github.com/dmlc/xgboost/issues/2073\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "clf._le = LabelEncoder().fit([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc(fname):\n",
    "    from subprocess import check_output\n",
    "    return int(check_output(f'wc -l {fname}', shell=True).decode('utf-8').split(' ')[0])\n",
    "\n",
    "n_read = 200000\n",
    "\n",
    "n_rows_total   = wc(fname)\n",
    "read_every_nth = int(n_rows_total / n_read)\n",
    "df_train = pd.read_csv(fname, nrows=n_read, skiprows=lambda x: x%read_every_nth)\n",
    "y_train = df_train['label']\n",
    "X_train = df_train.drop('label', axis=1)\n",
    "if 'ptbin' in X_train.columns: X_train = X_train.drop('ptbin', axis=1)\n",
    "\n",
    "n_rows_total   = wc(fname.replace('train', 'test'))\n",
    "read_every_nth = int(n_rows_total / n_read)\n",
    "df_test = pd.read_csv(fname.replace('train', 'test'), nrows=n_read, skiprows=lambda x: x%read_every_nth)\n",
    "y_test = df_test['label']\n",
    "X_test = df_test.drop('label', axis=1)\n",
    "if 'ptbin' in X_test.columns: X_test = X_test.drop('ptbin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train_pred), len(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs _feature_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import helper\n",
    "# reload(helper)\n",
    "# reload(helper.plotting)\n",
    "# reload(helper.plotting.performance_plots)\n",
    "# plot_score_vs_col = helper.plotting.plot_score_vs_col\n",
    "# plot_pdp = helper.plotting.plot_pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aver_pred(y_true, y_score):\n",
    "    return np.average(y_score)\n",
    "\n",
    "\n",
    "for feature,bins,bins_distplot in [\n",
    "                     ('Jet_Pt', (5,10,15,20,30,40,50,60,80,100), 100), \n",
    "                     ('Jet_Phi', 18*3, 10), \n",
    "                     ('Jet_Eta', 20, 100), \n",
    "                     ('Jet_NumTracks', np.arange(0,30,2), np.arange(0,30,1)),\n",
    "                      ]:\n",
    "    if feature not in X_train.columns: continue\n",
    "    for score in [(roc_auc_score, 'ROC AUC'), \n",
    "                  (partial(signal_eff, mistag_rate_thresh=1e-2), 'signal eff for mistag=1e-2'),\n",
    "                  (partial(signal_eff, mistag_rate_thresh=3e-2), 'signal eff for mistag=3e-2'),\n",
    "#                   (aver_pred, 'aver. score')\n",
    "                    ]:\n",
    "        ax=plot_score_vs_col(y_train, y_train_proba, \n",
    "#                       vals=scaler.inverse_transform(X_train)[:, df.columns.get_loc(feature) ], \n",
    "                      X_train[feature],\n",
    "                      bins=bins, bins_distplot=bins_distplot,\n",
    "                      score=score, color='b', label='train',\n",
    "                      show_distplot=True,                          \n",
    "                      show_errorbars=True,\n",
    "                     )\n",
    "        plot_score_vs_col(y_test, y_test_proba, \n",
    "#                           vals=scaler.inverse_transform(X_test)[:, df.columns.get_loc(feature) ],\n",
    "                          X_test[feature],\n",
    "                          bins=bins, bins_distplot=bins_distplot,\n",
    "                          score=score, color='r', marker='^', label='test', \n",
    "                          xlabel=feature,\n",
    "                          show_distplot=True,\n",
    "                          show_errorbars=True,\n",
    "                          ax=ax\n",
    "                         )\n",
    "        exp.log_figure(f\"{score[1].replace(' ', '').replace('=','-').replace('.', '-')}_vs_{feature.replace('Jet', '')}\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB's weight**   \n",
    "  = how many times feature was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dict = clf.get_booster().get_score(importance_type='weight')  # default only till xgboost-0.90\n",
    "imp = imp_dict.values()\n",
    "names = imp_dict.keys()\n",
    "# names = X.columns[[int(k[1:]) for k in imp_dict.keys()]]\n",
    "feature_importance_report(imp, names, importance_type='XGB\\'s weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB's total gain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dict = clf.get_booster().get_score(importance_type='total_gain')\n",
    "imp = imp_dict.values()\n",
    "names = imp_dict.keys()\n",
    "# names = X.columns[[int(k[1:]) for k in imp_dict.keys()]]\n",
    "feature_importance_report(imp, names, importance_type='XGB\\'s total_gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permutation importance**  \n",
    "remember to use scaled input data  \n",
    "it also quite time-consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = permutation_importance(clf,X_train[::20],y_train[::20])['importances_mean']\n",
    "feature_importance_report(imp, X_train.columns, importance_type='permutation imp.')\n",
    "perm_imp = imp\n",
    "perm_imp_feats = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial dependence plots\n",
    "for 5 features with highest permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dummy_scaler():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "#     def transform(self,x):\n",
    "#         return x\n",
    "#     def inverse_transform(self,x):\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# from sklearn.inspection import partial_dependence\n",
    "# from helper.plotting._utils import _add_distplot\n",
    "\n",
    "\n",
    "# def plot_pdp(clf, X, feature, scaler=None, column_names=None, query=None, \n",
    "#               xlabel=None, show_deciles=True, show_distplot=False, y=None, \n",
    "#               pardep_kws={}, plt_kws={}, distplot_kws={}, ax=None):\n",
    "#     \"\"\" plots partial dependence plot against `feature` for samples satifying `query`\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     clf : compatible with sklearn.inspect.parital_dependence\n",
    "#         model\n",
    "#     X : pd.DataFrame or 2D array of numbers\n",
    "#         data to calculated partial dependece\n",
    "#         both training and hold-on set (or combined) is reasonable for this purpose\n",
    "#     feature : str\n",
    "#         name of the feature to compute pdp w.r.t\n",
    "#     scaler : sklearn-compatible scaler e.g. StandardScaler\n",
    "#         scaler used to scale training data\n",
    "#     column_names : iterable of strings\n",
    "#         names of the columns in the dataset,\n",
    "#         if None (default) then X has to be dataframe with correct columns\n",
    "#         other args as `feature` or `query` relies on it\n",
    "#     query : str\n",
    "#         selection criteria, only samples passing it will be used to compute pdp\n",
    "#         has to be valid input for pd.DataFrame.query()\n",
    "#     xlabel : str or None\n",
    "#         xlabel, if None (default) `feature` will be used\n",
    "#     show_deciles : bool\n",
    "#         if small vertical lines (seaborn's rugs) corresponding to deciles of selected `feature` values should be shown,\n",
    "#         selected i.e. passing `query`\n",
    "#     show_distplot : bool\n",
    "#         if distribution of `feature` should be plotted below pdp\n",
    "#         if `y` passed, than it's grouped by y=0/1\n",
    "#     y : array of numbers\n",
    "#         samples labels, used to split distplot, \n",
    "#         used only if show_distplot is True\n",
    "#     pardep_kws : dict\n",
    "#         passed to sklearn.inspect.parital_dependence\n",
    "#     plt_kws : dict\n",
    "#         passed to plt.plot\n",
    "#     distplot_kws : dict\n",
    "#         passed to sns.distplot, \n",
    "#         has some defaults - see code\n",
    "#     ax : matplotlib.axes._subplots.AxesSubplot object or None\n",
    "#         axes to plot on\n",
    "#         default=None, meaning creating axes inside function\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     ax\n",
    "#     \"\"\"\n",
    "#     if not ax:\n",
    "#         _,ax = plt.subplots(figsize=(7,5))\n",
    "#     if column_names is None:\n",
    "#         column_names = X.columns\n",
    "\n",
    "\n",
    "#     X_orig = scaler.inverse_transform(X) if scaler else X \n",
    "#     df = pd.DataFrame(X_orig)\n",
    "#     df.columns = column_names\n",
    "#     if query: df = df.query(query)\n",
    "\n",
    "#     df_xgb = pd.DataFrame(scaler.transform(df)) if scaler else df\n",
    "#     if feat not in clf.get_booster().feature_names:\n",
    "#         df_xgb.columns = [f'f{i}' for i in range(df_xgb.shape[1])]\n",
    "#         feat_idx = list(column_names).index(feature)\n",
    "#         feat_name_xgb = f'f{feat_idx}'\n",
    "#     else: \n",
    "#         df_xgb.columns = df.columns\n",
    "#         feat_idx = list(column_names).index(feature)\n",
    "#         feat_name_xgb = feature\n",
    "        \n",
    "#     part_dep, feat_vals = partial_dependence(clf, df_xgb[df_xgb[feat_name_xgb].notna()], features=[feat_name_xgb], **pardep_kws)\n",
    "#     part_dep, feat_vals = np.array(part_dep[0]), np.array(feat_vals[0])\n",
    "#     if scaler: feat_vals_orig = feat_vals * np.sqrt(scaler.var_[feat_idx]) + scaler.mean_[feat_idx]\n",
    "#     else: feat_vals_orig = feat_vals\n",
    "\n",
    "#     ax.plot(feat_vals_orig, part_dep, lw=3, **plt_kws)\n",
    "#     ax.set_xlim(left=min(ax.get_xlim()[0], min(feat_vals_orig)), right=max(ax.get_xlim()[1], max(feat_vals_orig)))\n",
    "\n",
    "#     vals = df[feature]\n",
    "#     if show_deciles:\n",
    "#         xlim = ax.get_xlim()\n",
    "#         deciles = np.nanpercentile(vals, np.arange(0, 101, 10))\n",
    "#         sns.rugplot(deciles, ax=ax)\n",
    "#         ax.set_xlim(xlim)\n",
    "#     if show_distplot:\n",
    "#         distplot_default_kws = dict(bins=np.linspace(*ax.get_xlim(),100), distplot_y_frac=0.8)\n",
    "#         distplot_kws = {**distplot_default_kws, **distplot_kws}  # passed `distplot_kws` overwrites defaults\n",
    "#         _add_distplot(ax, vals, y=y, **distplot_kws)        \n",
    "\n",
    "#     ax.set_xlabel(xlabel if xlabel else feature)\n",
    "#     ax.set_ylabel('partial dependence')\n",
    "#     return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_imp_idx = np.argsort(perm_imp)[:-10:-1]\n",
    "features = X_train.columns[most_imp_idx]\n",
    "for feat in features:\n",
    "    ax = plot_pdp(clf, X_train[::10], feat, \n",
    "             scaler=None, \n",
    "             column_names = X_train.columns,\n",
    "             query='',\n",
    "             show_deciles=True,\n",
    "             show_distplot=True,\n",
    "             y=y_train[::10],\n",
    "             pardep_kws=dict(percentiles=(0.1,0.9)),\n",
    "            )\n",
    "    exp.log_figure(f\"pdp_{feat}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check pt distr train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Jet_Pt'].plot(figsize=(20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in [X_train['Jet_Pt'], X_test['Jet_Pt']]:\n",
    "    print(pt.mean(), pt.median(), np.percentile(pt,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in [X_train['Jet_Pt'][::2], X_train['Jet_Pt'][1::2]]:\n",
    "    print(pt.mean(), pt.median(), np.percentile(pt,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '\\n#\\n'.join(In)\n",
    "exp.set_code(code=code)\n",
    "In.clear()\n",
    "exp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
