{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import comet_ml\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as acc, f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.plotting import plot_roc, plot_score_vs_pt, plot_tagging_eff, plot_confusion_matrix, plot_xgb_learning_curve, plot_score_distr, plot_signal_significance\n",
    "from helper.utils import signal_eff, get_optimal_threshold, convert_float64_to_float32, save_model, printmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=16\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows_b    = 200000\n",
    "nrows_c    = 200000\n",
    "nrows_udsg = 200000\n",
    "\n",
    "skiprows   = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv('datasets/iter2/bjets_10-150GeV_base.csv', nrows=nrows_b, skiprows=range(1,skiprows))\n",
    "df_b['flavour'] = 'b'\n",
    "df_b = convert_float64_to_float32(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('datasets/iter2/cjets_10-150GeV_base.csv', nrows=nrows_c, skiprows=range(1,skiprows))\n",
    "df_c['flavour'] = 'c'\n",
    "df_c = convert_float64_to_float32(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_udsg = pd.read_csv('datasets/iter2/udsgjets_10-150GeV_base.csv', nrows=nrows_udsg, skiprows=range(1,skiprows))\n",
    "df_udsg['flavour'] = 'udsg'\n",
    "df_udsg = convert_float64_to_float32(df_udsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models from _comet.ml_\n",
    "\n",
    "TODO: \n",
    "- ?? select_best_model(metric='test_roc_auc', constrains='test_metric / train_metric < 1.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 12\n",
    "isinstance(x, (int,str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_exp(exp_id, model_type=XGBClassifier, featnames_type=(pd.Index, pd.Series, np.array, list), scaler_type=StandardScaler, api=comet_ml.API()):\n",
    "    exp = api.get(exp_id)\n",
    "    assets = exp.get_model_asset_list(exp.get_model_names()[0])\n",
    "    asset_id_model     = assets[  ['model' in a['fileName']     for a in assets].index(True)  ]['assetId']\n",
    "    asset_id_featnames = assets[  ['feat' in a['fileName'] for a in assets].index(True)  ]['assetId']\n",
    "    asset_id_scaler    = assets[  ['scaler' in a['fileName']    for a in assets].index(True)  ]['assetId']\n",
    "\n",
    "    model_bin = exp.get_asset(asset_id_model)\n",
    "    model = pickle.loads(model_bin)\n",
    "    assert isinstance(model, model_type)\n",
    "    \n",
    "    featnames_bin = exp.get_asset(asset_id_featnames)\n",
    "    featnames = pickle.loads(featnames_bin)\n",
    "    assert isinstance(featnames, featnames_type)\n",
    "    \n",
    "    scaler_bin = exp.get_asset(asset_id_scaler)\n",
    "    scaler = pickle.loads(scaler_bin)\n",
    "    assert isinstance(scaler, scaler_type)\n",
    "    \n",
    "    return model, np.array(featnames), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id_bc_vs_udsg = 'phd/bc-vs-udsg/bcf99db8f5a94b2184e6e13161c50bbe'\n",
    "# exp_id_bc_vs_udsg = 'phd/bc-vs-udsg/61c014a2ff7c49e8bae9ec466ffaa998'\n",
    "exp_id_b_vs_c     = 'phd/b-vs-c/3ce14e4e99d54283bc66eb24c98b6468' \n",
    "clf_bc_vs_udsg , feats_bc_vs_udsg, scaler_bc_vs_udsg = get_model_from_exp(exp_id_bc_vs_udsg)\n",
    "clf_b_vs_c     , feats_b_vs_c    , scaler_b_vs_c     = get_model_from_exp(exp_id_b_vs_c)\n",
    "feats_all = np.unique(np.hstack([feats_bc_vs_udsg, feats_b_vs_c]))\n",
    "\n",
    "def short_exp_id(exp_id):\n",
    "    return exp_id.split('/')[-1][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler_bc_vs_udsg.transform(df_b[feats_bc_vs_udsg])\n",
    "y_b_proba_bc_vs_udsg = clf_bc_vs_udsg.predict_proba(X)[:,1]\n",
    "X = scaler_b_vs_c.transform(df_b[feats_b_vs_c])\n",
    "y_b_proba_b_vs_c = clf_b_vs_c.predict_proba(X)[:,1]\n",
    "\n",
    "X = scaler_bc_vs_udsg.transform(df_c[feats_bc_vs_udsg])\n",
    "y_c_proba_bc_vs_udsg = clf_bc_vs_udsg.predict_proba(X)[:,1]\n",
    "X = scaler_b_vs_c.transform(df_c[feats_b_vs_c])\n",
    "y_c_proba_b_vs_c = clf_b_vs_c.predict_proba(X)[:,1]\n",
    "\n",
    "X = scaler_bc_vs_udsg.transform(df_udsg[feats_bc_vs_udsg])\n",
    "y_udsg_proba_bc_vs_udsg = clf_bc_vs_udsg.predict_proba(X)[:,1]\n",
    "X = scaler_b_vs_c.transform(df_udsg[feats_b_vs_c])\n",
    "y_udsg_proba_b_vs_c = clf_b_vs_c.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D histos / scatterplots for each flavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "alpha = 0.25\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "ax.plot(y_udsg_proba_bc_vs_udsg[:n], y_udsg_proba_b_vs_c[:n], ',', c='b', alpha=alpha)\n",
    "ax.plot(y_c_proba_bc_vs_udsg[:n], y_c_proba_b_vs_c[:n], ',', c='orange', alpha=alpha)\n",
    "ax.plot(y_b_proba_bc_vs_udsg[:n], y_b_proba_b_vs_c[:n], ',', c='r', alpha=alpha)\n",
    "ax.set_xlabel('score bc vs udsg')\n",
    "ax.set_ylabel('score b vs c')\n",
    "plt.savefig(f'scores_2BDTs_all-flavours_{short_exp_id(exp_id_bc_vs_udsg)}-{short_exp_id(exp_id_b_vs_c)}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_proba_bc_vs_udsg, y_proba_b_vs_c, flavour in zip(\n",
    "                                        [y_udsg_proba_bc_vs_udsg, y_c_proba_bc_vs_udsg, y_b_proba_bc_vs_udsg],\n",
    "                                        [y_udsg_proba_b_vs_c,     y_c_proba_b_vs_c,     y_b_proba_b_vs_c],\n",
    "                                        ['udsg',                  'c',                  'b'],\n",
    "                                    ):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.hist2d(y_proba_bc_vs_udsg, y_proba_b_vs_c, bins=50, norm=mpl.colors.LogNorm(), vmin=10, vmax=3000);\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('score bc vs udsg')\n",
    "    plt.ylabel('score b vs c')\n",
    "    plt.title(f'{flavour}-jets')\n",
    "    plt.savefig(f'scores_2BDTs_{flavour}_{short_exp_id(exp_id_bc_vs_udsg)}-{short_exp_id(exp_id_b_vs_c)}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance plots for given thresholds\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
