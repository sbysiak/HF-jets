{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import numba\n",
    "\n",
    "# import helper.preprocessing.apply_cut\n",
    "from helper.preprocessing import add_sorting_index, add_sorted_col, add_nth_val, apply_cut\n",
    "from helper.utils import convert_float64_to_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=16\n",
    "CACHE = dict()\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "# pd.options.display.max_colwith = 100\n",
    "pd.set_option('max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../ana_results/iter2/LHC16h3/'\n",
    "tree_name_core = 'JetTree_AliAnalysisTaskJetExtractor_Jet_AKTChargedR040_tracks_pT0150_E_scheme_'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def `add_features()` function\n",
    "see: https://github.com/sbysiak/HF-jets/blob/master/analyses/helper/preprocessing/nested_features.py for docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T08:45:57.107180Z",
     "start_time": "2019-10-29T08:45:57.096489Z"
    }
   },
   "source": [
    "__JET:__ 'Jet_Pt', 'Jet_Phi', 'Jet_Eta', 'Jet_Area', 'Jet_NumTracks',  \n",
    "\n",
    "__EVENT:__ 'Event_BackgroundDensity', 'Event_BackgroundDensityMass', 'Event_Vertex_X', 'Event_Vertex_Y', 'Event_Vertex_Z',  \n",
    "'Event_Centrality', 'Event_Multiplicity', 'Event_ID', 'Event_MagneticField', 'Event_PtHard', 'Event_Weight', 'Event_ImpactParameter', \n",
    "\n",
    "__TRACKS:__\n",
    "'Jet_Track_Pt', 'Jet_Track_Phi', 'Jet_Track_Eta', 'Jet_Track_Charge', 'Jet_Track_Label',   \n",
    "'Jet_Track_IPd', 'Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz', 'Jet_Track_ProdVtx_X', 'Jet_Track_ProdVtx_Y', 'Jet_Track_ProdVtx_Z',\n",
    "       \n",
    "__TRACKS-PID:__ 'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', 'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth', \n",
    "\n",
    "__SHAPE:__ ' \n",
    "Jet_Shape_Mass_NoCorr', 'Jet_Shape_Mass_DerivCorr_1', 'Jet_Shape_Mass_DerivCorr_2',  \n",
    "'Jet_Shape_pTD_DerivCorr_1',  'Jet_Shape_pTD_DerivCorr_2', 'Jet_Shape_LeSub_NoCorr', 'Jet_Shape_LeSub_DerivCorr',  \n",
    "'Jet_Shape_Angularity', 'Jet_Shape_Angularity_DerivCorr_1', 'Jet_Shape_Angularity_DerivCorr_2',  \n",
    "'Jet_Shape_Circularity_DerivCorr_1', 'Jet_Shape_Circularity_DerivCorr_2', 'Jet_Shape_Sigma2_DerivCorr_1', 'Jet_Shape_Sigma2_DerivCorr_2',   \n",
    "'Jet_Shape_NumTracks_DerivCorr', 'Jet_Shape_MomentumDispersion', 'Jet_Shape_TrackPtMean',   'Jet_Shape_TrackPtMedian', \n",
    "       \n",
    "__SPLITTINGS:__'\n",
    "Jet_NumSplittings', 'Jet_Splitting_Theta', 'Jet_Splitting_RadiatorE', 'Jet_Splitting_kT', 'Jet_Splitting_SecVtx_Rank', 'Jet_Splitting_SecVtx_Index',\n",
    "       \n",
    "__MC:__ 'Jet_MC_MotherParton', 'Jet_MC_MotherHadron', 'Jet_MC_MotherIC', 'Jet_MC_TruePtFraction', 'Jet_MC_TruePtFraction_PartLevel',\n",
    "  \n",
    "__SEC. VERTEX:__ 'Jet_NumSecVertices', 'Jet_SecVtx_X', 'Jet_SecVtx_Y', 'Jet_SecVtx_Z', 'Jet_SecVtx_Mass', 'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion', \n",
    "\n",
    "__TRIGGER:__' Jet_NumTriggerTracks', 'Jet_TriggerTrack_Pt', 'Jet_TriggerTrack_dEta', 'Jet_TriggerTrack_dPhi', 'Jet_Track_IPdNsigma', 'Jet_SecVtx_LxyNSigma',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "\n",
    "#     def IPdNSigmaAbs_cutSmallSigma(row):\n",
    "#         pt = row['Jet_Track_Pt']\n",
    "#         IPd_sigma = np.sqrt(row['Jet_Track_CovIPd'])\n",
    "#         sigma_threshold = 0.004444561*pt**(-0.4790711) if pt < 10 else 0.0016\n",
    "#         if IPd_sigma > sigma_threshold:\n",
    "#             return abs(row['Jet_Track_IPd'] / IPd_sigma)\n",
    "#         else:\n",
    "#             return -1\n",
    "    \n",
    "    \n",
    "    def subtract_phi(phi1, phi2):\n",
    "        diff = phi1-phi2\n",
    "        if abs(diff) <= np.pi: return diff\n",
    "        elif diff > np.pi: return diff - 2*np.pi\n",
    "        elif diff < -np.pi: return diff + 2*np.pi\n",
    "\n",
    "\n",
    "    def subtract_eta(eta1, eta2):\n",
    "        diff = eta1-eta2\n",
    "        return diff\n",
    "    \n",
    "    # add custom features\n",
    "    df['Jet_Track_DeltaPhi'] = df.apply(lambda row: np.array([ subtract_phi(tr_phi, row['Jet_Phi']) for tr_phi in row['Jet_Track_Phi']]), axis=1)\n",
    "    df['Jet_Track_DeltaEta'] = df.apply(lambda row: np.array([ subtract_eta(tr_eta, row['Jet_Eta']) for tr_eta in row['Jet_Track_Eta']]), axis=1)\n",
    "    df['Jet_Track_DeltaR']   = df.apply(lambda row: np.array([ np.sqrt(tr_phi**2 + tr_eta**2)       for tr_phi, tr_eta in zip(row['Jet_Track_DeltaPhi'], row['Jet_Track_DeltaEta'])]), axis=1)\n",
    "    df['Jet_Track_PtFrac']   = df.apply(lambda row: np.array([ (tr_pt/row['Jet_Pt'])                for tr_pt in row['Jet_Track_Pt']]), axis=1)\n",
    "#     df = df.drop(['Jet_Track_Phi', 'Jet_Track_Eta'])\n",
    "# IPdNsigma, IPzNsigma, IP3dNsigma\n",
    "# \n",
    "\n",
    "#     df['Jet_Track_IPdNsigmaAbs']  = df.apply(lambda row: abs(row['Jet_Track_IPd'] / np.sqrt(row['Jet_Track_CovIPd'])), axis=1)\n",
    "#     df['Jet_Track_IPdNsigmaAbs']  = df.apply(lambda row: IPdNsigmaAbs_cutSmallSigma(row), axis=1)\n",
    "    df['Jet_Track_IPdSigma']  = df['Jet_Track_CovIPd'].pow(0.5)\n",
    "    df['Jet_Track_IPzSigma']  = df['Jet_Track_CovIPz'].pow(0.5)\n",
    "    df = df.drop(['Jet_Track_CovIPd', 'Jet_Track_CovIPz'], axis=1)\n",
    "    \n",
    "    df['Jet_Track_IPdAbs']          = eval('abs(a)', dict(a=df['Jet_Track_IPd'])) \n",
    "    df['Jet_Track_IPzAbs']          = eval('abs(a)', dict(a=df['Jet_Track_IPz'])) \n",
    "    df['Jet_Track_IPdNsigma']       = eval('a/b', dict(a=df['Jet_Track_IPd'], b=df['Jet_Track_IPdSigma'])) \n",
    "    df['Jet_Track_IPzNsigma']       = eval('a/b', dict(a=df['Jet_Track_IPz'], b=df['Jet_Track_IPzSigma'])) \n",
    "    df['Jet_Track_IPdNsigmaAbs']    = eval('abs(a)/b', dict(a=df['Jet_Track_IPd'], b=df['Jet_Track_IPdSigma'])) \n",
    "    df['Jet_Track_IPzNsigmaAbs']    = eval('abs(a)/b', dict(a=df['Jet_Track_IPz'], b=df['Jet_Track_IPzSigma'])) \n",
    "\n",
    "#     def cut_val(track_pt):\n",
    "#         return 0.004444561*track_pt**(-0.4790711) if track_pt < 10 else 0.0015\n",
    "    \n",
    "#     df['Jet_Track_CutIPdSigmaVSPt'] = df.apply(lambda row: \n",
    "#                                         np.array([int(ipd_sigma < cut_val(pt))  for ipd_sigma, pt in zip(row['Jet_Track_IPdSigma'], row['Jet_Track_Pt'])]),\n",
    "#                                         axis=1\n",
    "#                                       )\n",
    "#     df = df.drop(['Jet_Track_IPd', ], axis=1)\n",
    "#     df = df.drop(['Jet_Track_IPd', 'Jet_Track_IPz'], axis=1)\n",
    "    \n",
    "    df['Jet_SecVtx_LxyNsigma'] = eval('a / b', dict(a=df['Jet_SecVtx_Lxy'], b=df['Jet_SecVtx_SigmaLxy']))\n",
    "    \n",
    "    ### create index cols\n",
    "    track_sorting_var = 'IPdNsigmaAbs'\n",
    "    sv_sorting_var    = 'LxyNsigma'\n",
    "    add_sorting_index(df, f'Jet_Track_{track_sorting_var}', 'desc')\n",
    "    add_sorting_index(df, f'Jet_SecVtx_{sv_sorting_var}', 'desc')\n",
    "\n",
    "    ### apply cuts a.k.a. filter index cols\n",
    "#     apply_cut(df, 'Jet_Track_IPdNsigmaAbs < 50', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_Track_Pt > 0.5', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_Track_CutIPdSigmaVSPt < 0.5', track_sorting_var, 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_Chi2 < 10' ,'LxyNsigma', 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_Dispersion < 0.01' ,'LxyNsigma', 'desc')\n",
    "#     apply_cut(df, 'Jet_SecVtx_SigmaLxy < 0.1' ,'LxyNsigma', 'desc')\n",
    "    \n",
    "    ### create sorted cols\n",
    "    track_params = ['Jet_Track_Pt', 'Jet_Track_Phi', 'Jet_Track_Eta', \n",
    "                    'Jet_Track_DeltaPhi', 'Jet_Track_DeltaEta', 'Jet_Track_PtFrac', 'Jet_Track_DeltaR',\n",
    "                    'Jet_Track_Charge', 'Jet_Track_Label', \n",
    "                    'Jet_Track_IPd', 'Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz', \n",
    "                    'Jet_Track_ProdVtx_X', 'Jet_Track_ProdVtx_Y', 'Jet_Track_ProdVtx_Z',\n",
    "                   \n",
    "                    'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', \n",
    "                    'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth',\n",
    "                    \n",
    "                    'Jet_Track_IPdAbs'      , 'Jet_Track_IPzAbs',\n",
    "                    'Jet_Track_IPdSigma'    , 'Jet_Track_IPzSigma',\n",
    "                    'Jet_Track_IPdNsigma'   , 'Jet_Track_IPzNsigma',  \n",
    "                    'Jet_Track_IPdNsigmaAbs', 'Jet_Track_IPzNsigmaAbs',\n",
    "                   ]\n",
    "    \n",
    "    sv_params    = ['Jet_SecVtx_X', 'Jet_SecVtx_Y', 'Jet_SecVtx_Z', \n",
    "                    'Jet_SecVtx_Mass', \n",
    "                    'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion', 'Jet_SecVtx_LxyNsigma',\n",
    "                   ]\n",
    "    \n",
    "    track_params = [par for par in track_params if par in df.columns]\n",
    "    sv_params    = [par for par in  sv_params   if par in df.columns]\n",
    "\n",
    "    for param in track_params:\n",
    "        add_sorted_col(df, param ,   track_sorting_var, 'desc')\n",
    "\n",
    "    for param in sv_params:\n",
    "        add_sorted_col(df, param ,   sv_sorting_var, 'desc')\n",
    "\n",
    "    \n",
    "    ### extract n-th value from sorted cols\n",
    "#     new_training_cols = []\n",
    "    n_tracks, n_sv = 10,10\n",
    "    for param in track_params:\n",
    "        for i in range(n_tracks):\n",
    "            add_nth_val(df, col_name=f'{param}__sortby__{track_sorting_var}__desc', n=i, fillna=None)\n",
    "#             new_training_cols.append(df.columns[-1])\n",
    "\n",
    "    for param in sv_params:\n",
    "        for i in range(n_sv):\n",
    "            add_nth_val(df, col_name=f'{param}__sortby__{sv_sorting_var}__desc', n=i, fillna=None)\n",
    "#             new_training_cols.append(df.columns[-1])\n",
    "\n",
    "    ### drop temporary columns, i.e. those containing arrays, like 'Index__*' as well as initial columns used for extraction, like 'Jet_Track_Pt'\n",
    "#     columns_to_keep = df.select_dtypes(exclude=['object']).columns\n",
    "    columns_to_keep = [col for col,val in zip(df.columns, df.iloc[0]) if not hasattr(val, '__iter__') or isinstance(val, str)]\n",
    "    return df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cols = ['Jet_Pt', \n",
    "                 'Jet_Phi', 'Jet_Eta', \n",
    "                 'Jet_Area', 'Jet_NumTracks',\n",
    "            'Jet_Track_Pt', 'Jet_Track_Phi', 'Jet_Track_Eta', \n",
    "                 'Jet_Track_IPd','Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz',\n",
    "#             'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', 'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth',\n",
    "            'Jet_SecVtx_Mass', 'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion',\n",
    "\n",
    "#             'Jet_Shape_Mass_NoCorr', 'Jet_Shape_Mass_DerivCorr_1', 'Jet_Shape_Mass_DerivCorr_2',\n",
    "#             'Jet_Shape_pTD_DerivCorr_1', 'Jet_Shape_pTD_DerivCorr_2', 'Jet_Shape_LeSub_NoCorr', 'Jet_Shape_LeSub_DerivCorr',\n",
    "#             'Jet_Shape_Angularity', 'Jet_Shape_Angularity_DerivCorr_1', 'Jet_Shape_Angularity_DerivCorr_2',\n",
    "#             'Jet_Shape_Circularity_DerivCorr_1', 'Jet_Shape_Circularity_DerivCorr_2', 'Jet_Shape_Sigma2_DerivCorr_1', 'Jet_Shape_Sigma2_DerivCorr_2',\n",
    "#             'Jet_Shape_NumTracks_DerivCorr', 'Jet_Shape_MomentumDispersion', 'Jet_Shape_TrackPtMean', 'Jet_Shape_TrackPtMedian',\n",
    "                ]\n",
    "\n",
    "froot = uproot.open(os.path.join(data_dir, 'ptbin1/AnalysisResults.root'))\n",
    "df = froot[tree_name_core+'bJets'].pandas.df(flatten=False, branches=training_cols).query('Jet_Pt > 10 and Jet_Pt < 100')\n",
    "print('tree reading done')\n",
    "df_after = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read to dataframes & add features & write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading steps are:  \n",
    "`for f in files:`  \n",
    "`...   for batch in f:`  \n",
    "`... ...  read`  \n",
    "`... ...  process`  \n",
    "`... ...  write to csv`\n",
    "\n",
    "it's also possible to use generators from `uproot` but there is some performance issue:  \n",
    "`generator = froot[tree_name_core+'udsgJets'].iterate(entrysteps=iter_entries, outputtype=pd.DataFrame)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_to_read = ['Jet_Pt', 'Jet_Phi', 'Jet_Eta', 'Jet_Area', 'Jet_NumTracks',\n",
    "            'Jet_Track_Pt', 'Jet_Track_Phi', 'Jet_Track_Eta', \n",
    "            'Jet_Track_IPd','Jet_Track_IPz', 'Jet_Track_CovIPd', 'Jet_Track_CovIPz',\n",
    "#             'Jet_Track_PID_ITS', 'Jet_Track_PID_TPC', 'Jet_Track_PID_TOF', 'Jet_Track_PID_TRD', 'Jet_Track_PID_Reconstructed', 'Jet_Track_PID_Truth',\n",
    "            'Jet_SecVtx_Mass', 'Jet_SecVtx_Lxy', 'Jet_SecVtx_SigmaLxy', 'Jet_SecVtx_Chi2', 'Jet_SecVtx_Dispersion',\n",
    "                    \n",
    "#             'Jet_Shape_Mass_NoCorr', 'Jet_Shape_Mass_DerivCorr_1', 'Jet_Shape_Mass_DerivCorr_2',\n",
    "#             'Jet_Shape_pTD_DerivCorr_1', 'Jet_Shape_pTD_DerivCorr_2', 'Jet_Shape_LeSub_NoCorr', 'Jet_Shape_LeSub_DerivCorr',\n",
    "#             'Jet_Shape_Angularity', 'Jet_Shape_Angularity_DerivCorr_1', 'Jet_Shape_Angularity_DerivCorr_2',\n",
    "#             'Jet_Shape_Circularity_DerivCorr_1', 'Jet_Shape_Circularity_DerivCorr_2', 'Jet_Shape_Sigma2_DerivCorr_1', 'Jet_Shape_Sigma2_DerivCorr_2',\n",
    "#             'Jet_Shape_NumTracks_DerivCorr', 'Jet_Shape_MomentumDispersion', 'Jet_Shape_TrackPtMean', 'Jet_Shape_TrackPtMedian',\n",
    "            ]\n",
    "\n",
    "query_str = 'Jet_Pt > 10 and Jet_Pt < 150'  \n",
    "\n",
    "custom_name = 'Tr-sortbyIPdNsigmaAbs-noCuts_SV-sortbyLxyNsigma-noCuts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_iter = 100000\n",
    "n_to_be_saved = 1e6  # per input file = per hard-pt-bin\n",
    "\n",
    "for d in sorted(os.listdir(data_dir), key=lambda x: int(x.replace('ptbin','').replace('1-2', '3'))):\n",
    "    print(d)\n",
    "    if '-' in d: \n",
    "        print('\\t\\t-- skipping')\n",
    "        continue\n",
    "    froot = uproot.open(os.path.join(data_dir, d, 'AnalysisResults.root'))\n",
    "    for flavour in ['b', 'c', 'udsg']:\n",
    "        print('\\t', flavour)\n",
    "        tree = froot[tree_name_core+f'{flavour}Jets']\n",
    "        \n",
    "        tic = time()\n",
    "        n_saved = 0\n",
    "        for i in range(99999):\n",
    "            if i*n_per_iter > tree.numentries: break\n",
    "            df = tree.pandas.df(flatten=False, branches=branches_to_read, entrystart=i*n_per_iter, entrystop=(i+1)*n_per_iter).query(query_str)\n",
    "            \n",
    "            df = convert_float64_to_float32(df)\n",
    "            print('\\t\\t adding features...')\n",
    "            df = add_features(df)\n",
    "            df['ptbin'] = d\n",
    "            df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "            print(f'\\t\\tN = {len(df)} \\t exec. time = {time() - tic} sec ')  \n",
    "            df.to_csv(f'{flavour}jets_10-150GeV_{custom_name}_{d}_{i}.csv', index=False)\n",
    "            n_saved += len(df)\n",
    "            print(f'\\t\\titer {i} done, {n_saved} rows saved')\n",
    "            if n_saved > n_to_be_saved: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__investigate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Jet_Pt'].describe(percentiles=[0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sum(df_b.memory_usage(deep=True))/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T11:07:57.344Z"
    }
   },
   "source": [
    "__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(add_features)\n",
    "with open(f'add_features_10-150GeV_{custom_name}.txt', 'w') as fout:\n",
    "    fout.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__real data, all flavours__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = '../ana_results/iter2/LHC15n/AnalysisResults.root'\n",
    "\n",
    "froot = uproot.open(data_fpath)\n",
    "tree = froot[tree_name_core+'allJets']\n",
    "\n",
    "n_per_iter = 1000000\n",
    "n_to_be_saved = 1e9\n",
    "n_saved = 0\n",
    "for i in range(99999):\n",
    "    tic = time()\n",
    "    if i*n_per_iter >= tree.numentries: break\n",
    "    df = tree.pandas.df(flatten=False, branches=branches_to_read, entrystart=i*n_per_iter, entrystop=(i+1)*n_per_iter).query(query_str)\n",
    "\n",
    "    df = convert_float64_to_float32(df)\n",
    "    print('\\t adding features...')\n",
    "    df = add_features(df)\n",
    "    df['ptbin'] = 'data'\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    print(f'\\tN = {len(df)} \\t exec. time = {time() - tic} sec ')  \n",
    "    df.to_csv(f'alljets_10-150GeV_{custom_name}_{i}.csv', index=False)\n",
    "    n_saved += len(df)\n",
    "    print(f'\\titer {i} done, {n_saved} rows saved')\n",
    "    if n_saved >= n_to_be_saved: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from helper.utils import convert_float64_to_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flavour = 'all'\n",
    "custom_name = 'Tr-sortbyPt-cuts-IPdLT02_SV-sortbyDispersion-noCuts'\n",
    "core = f'{flavour}jets_10-150GeV_{custom_name}'\n",
    "output_fname = core+'.csv'\n",
    "pattern = core+'_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob(pattern))\n",
    "df_merged = pd.concat([convert_float64_to_float32(pd.read_csv(f)) for f in glob(pattern)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample in order to remove pt-dependence of index\n",
    "df_merged = df_merged.sample(frac=1, random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_fname)\n",
    "df_merged.to_csv(output_fname,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
